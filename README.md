# Deep Learning with PyTorch

*Некоторые базовые задачи глубокого обучения с использованием фреймворка PyTorch.*


## Знакомство с PyTorch

В данном задании попробуем апроксимировать функцию косинуса на некотором малом отрезке с помощью простой трехслойной полносвязной нейросети.

[Ноутбук](./Introduction_in_Pytorch.ipynb)

## Классификация рукописных цифр на датасете MNIST

В данном задании необходимо научиться распознавать изображения рукописных цифр. Датасет представлен в виде чернобелых изображений цифр. Таким образом каждый сэмпл датасета - матрица 28х28. Представим изображение в виде одномерного вектора и используем полносвязную нейронную сеть с выходным вектором размерности 10 - распределение вероятностей пренадлежности к тому или иному классу (каждый класс - соответсвующее число).

[Ноутбук](./MNIST_classification.ipynb)

## Классификация изображений на датасете CIFAR10 (полносвязная нейросеть)

Попробуем применить подход с полносвязной нейронной сетью, как и в предыдущих заданиях. Получим неудовлетворительные результаты. Такой результат объясняется плохой работой обычных полносвязных сетей для обработки изображений, как минимум потому что ключевые объекты на изображении, которые мы учимся классифицировать на данном датасете, могут быть расположены в разных позициях на самом изображении. (Отмечу здесь, что хорошие результаты на датасета MNIST из предыдущего задания были получены за счет хорошей преобработки изображений датасета, а также их простой стуктуры). В целом для получения хороших результатов стоит применять сверточные нейронные сети, речь о которых пойдет в следующих задачах.

[Ноутбук](./CIFAR_Classification.ipynb)


*Замечание:*

Рассмотрим принцип работы свертки на примере [фильтра Собеля](./Sobel_filter.ipynb).


Фильтр Собеля позволяет выделять горизонтальные или вертикальные линии. В общем же смысле свертка позволяет выделять и более сложные паттерны, для этого достаточно сделать этот слой также обучаемым, а точнее сделать обучаемыми веса в картах активаций. 

## Классификация изображений на датасете CIFAR10 (сверточная нейросеть)

В данном случае к предыдущей задаче попробуем применить подход использования сверток. Наблюдам улучшение показателей модели. Стоит отметить, что использованиеим сверточной нейронной сети может позволить получить результаты намного лучше, но для этого нужно подобрать более оптимальную архитектуру слоев нейросети. Тем не менее, пример данной задачи показывает, что сверточный подход для работы с изображениями заметно лучше, чем простая полносвязная нейронная сеть. 

[Ноутбук](./CIFAR_Classification_CNN.ipynb)

## Классификация изображений с использованием подхода Transfer Learning

Возьмем предобученную нейросеть ResNET-18, которая умеет определять 1000 классов, и заменим последний слой на необходимое для нашего датасета число классов - 70. Также заморозим некоторые первые слои (слои сверток), то есть градиентная оптимизация не будет менять их весовые значения (Это хороший подход, так как слои свертки в исходной архитектуре сети учатся определять первичные паттерны, а полносвязные слои - уже классифицировать изображения). 

[Ноутбук](./TransferLearningDogsClassification.ipynb)



*Замечание:* Работа с текстовыми данными, векторизация слов [Заметка Word2Vec](./Note_word2vec.ipynb)